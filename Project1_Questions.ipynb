{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHF1vrO5tVk3"
   },
   "source": [
    "https://rpg.stackexchange.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "whL6xghjtEBn"
   },
   "outputs": [],
   "source": [
    "# Get our post reader and open the xml file\n",
    "from post_parser_record import PostParserRecord\n",
    "#post_reader = PostParserRecord(\"data/Posts.xml\")\n",
    "post_reader = PostParserRecord(\"data/Posts_Small.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czJoitbpt4Aw",
    "outputId": "acdac149-81dc-4f13-f5a3-89838305ccdf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Thoeu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Thoeu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus.reader.tagged import word_tokenize\n",
    "import re, string\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aQIKF_x0t6yI"
   },
   "outputs": [],
   "source": [
    "# Get our collection of words : count\n",
    "word_dict = {}\n",
    "\n",
    "# For each question\n",
    "for answer_id in post_reader.map_questions:\n",
    "  # Get the text\n",
    "  text = (post_reader.map_questions[answer_id].title + \" \" + post_reader.map_questions[answer_id].body)\n",
    "\n",
    "  # Remove punctuations, make lowercase\n",
    "  token_words = re.sub(\"<.*?>|\\\\n|&quot;\", \" \", text.lower())\n",
    "  token_words = word_tokenize(token_words.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "  # Go through all the words and add them to the dictionary with count\n",
    "  for word in token_words:\n",
    "    if word not in stopwords.words('english'):\n",
    "      if word in word_dict:\n",
    "        docs = word_dict[word]\n",
    "        if answer_id not in docs:\n",
    "          docs.update({answer_id:1})\n",
    "        else:\n",
    "          count = docs[answer_id]\n",
    "          docs[answer_id] = count+1\n",
    "        word_dict[word] = docs\n",
    "      else:\n",
    "        docs = {answer_id:1}\n",
    "        word_dict[word] = docs\n",
    "\n",
    "# For each question\n",
    "for answer_id in post_reader.map_just_answers:\n",
    "  # Get the text\n",
    "  text = (post_reader.map_just_answers[answer_id].body)\n",
    "\n",
    "  # Remove punctuations, make lowercase\n",
    "  token_words = re.sub(\"<.*?>|\\\\n|&quot;\", \" \", text.lower())\n",
    "  token_words = word_tokenize(token_words.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "  # Go through all the words and add them to the dictionary with count\n",
    "  for word in token_words:\n",
    "    if word not in stopwords.words('english'):\n",
    "      if word in word_dict:\n",
    "        docs = word_dict[word]\n",
    "        if answer_id not in docs:\n",
    "          docs.update({answer_id:1})\n",
    "        else:\n",
    "          count = docs[answer_id]\n",
    "          docs[answer_id] = count+1\n",
    "        word_dict[word] = docs\n",
    "      else:\n",
    "        docs = {answer_id:1}\n",
    "        word_dict[word] = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5IoIkOu2Dlj",
    "outputId": "5b5f6f7d-0e84-49ed-b0eb-681a05c2890b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of words for the answers are: 78.0\n",
      "The average number of words for the questions are: 155.0\n"
     ]
    }
   ],
   "source": [
    "# Average number of words in answers\n",
    "number_answers = len(post_reader.map_just_answers.keys())\n",
    "number_words = 0\n",
    "# loop through every answer in the map via answer_id\n",
    "for answer_id in post_reader.map_just_answers:\n",
    "  answer = post_reader.map_just_answers[answer_id]\n",
    "  number_words += len(answer.body.split(\" \"))\n",
    "\n",
    "print(\"The average number of words for the answers are: \" + str(number_words/number_answers))\n",
    "\n",
    "# Average number of words in questions\n",
    "number_answers = len(post_reader.map_questions.keys())\n",
    "number_words = 0\n",
    "# loop through every answer in the map via answer_id\n",
    "for answer_id in post_reader.map_questions:\n",
    "  question = (post_reader.map_questions[answer_id].title + \" \" + post_reader.map_questions[answer_id].body)\n",
    "  number_words += len(answer.body.split(\" \"))\n",
    "\n",
    "print(\"The average number of words for the questions are: \" + str(number_words/number_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "kx9bCEWr2qL_",
    "outputId": "ce40df7f-2013-4962-a3b9-5ae3a1d60ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of answers given to each question is 8.142857142857142\n",
      "0 questions have no answers.\n",
      "16 questions have accepted answers.\n"
     ]
    }
   ],
   "source": [
    "# Average number of answers given to each question\n",
    "number_questions = len(post_reader.map_questions)\n",
    "number_answers = 0\n",
    "for answer_id in post_reader.map_questions:\n",
    "  number_answers += post_reader.map_questions[answer_id].answer_count\n",
    "\n",
    "print(\"The average number of answers given to each question is \" + str(number_answers/number_questions))\n",
    "\n",
    "# Questions without answers\n",
    "no_answers = 0\n",
    "for answer_id in post_reader.map_questions:\n",
    "  if(post_reader.map_questions[answer_id].answer_count == 0):\n",
    "    no_answers += 1\n",
    "print(str(no_answers) + \" questions have no answers.\")\n",
    "\n",
    "# Questions with an accepted answer\n",
    "accepted_answers = 0\n",
    "# go through every question and check if it has an accepted answer, add to count if so\n",
    "for answer_id in post_reader.map_questions:\n",
    "  if(post_reader.map_questions[answer_id].accepted_answer_id != None):\n",
    "    accepted_answers += 1\n",
    "\n",
    "print(str(accepted_answers) + \" questions have accepted answers.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "20bb238cb4edfc908a8110d107a0ddda64e31c12ae4c88da80c70bf5a804564a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
